# 목차
- 2: [프로세스와 스레드 소개](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-2-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%86%8C%EA%B0%9C)
- 3: [스레드 생성과 실행](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-3-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%83%9D%EC%84%B1%EA%B3%BC-%EC%8B%A4%ED%96%89)
- 4: [스레드 제어와 생명 주기 1](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-4-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%A0%9C%EC%96%B4%EC%99%80-%EC%83%9D%EB%AA%85-%EC%A3%BC%EA%B8%B0-1)
- 5: [스레드 제어와 생명 주기 2](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-5-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%A0%9C%EC%96%B4%EC%99%80-%EC%83%9D%EB%AA%85-%EC%A3%BC%EA%B8%B0-2)
- 6: [메모리 가시성](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-6-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B0%80%EC%8B%9C%EC%84%B1)
- 7: [동기화 - synchronized](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-7-%EB%8F%99%EA%B8%B0%ED%99%94---synchronized)
- 8: [고급 동기화 - concurrent.Lock](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-8-%EA%B3%A0%EA%B8%89-%EB%8F%99%EA%B8%B0%ED%99%94---concurrentlock)
- 9: [생산자 소비자 문제 1](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-9-%EC%83%9D%EC%82%B0%EC%9E%90-%EC%86%8C%EB%B9%84%EC%9E%90-%EB%AC%B8%EC%A0%9C-1)
- 10: [생산자 소비자 문제 1](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-10-%EC%83%9D%EC%82%B0%EC%9E%90-%EC%86%8C%EB%B9%84%EC%9E%90-%EB%AC%B8%EC%A0%9C-2)
- 11: [CAS - 동기화와 원자적 연산](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-11-cas---%EB%8F%99%EA%B8%B0%ED%99%94%EC%99%80-%EC%9B%90%EC%9E%90%EC%A0%81-%EC%97%B0%EC%82%B0)
- 12: [동시성 컬렉션](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-12-%EB%8F%99%EC%8B%9C%EC%84%B1-%EC%BB%AC%EB%A0%89%EC%85%98)
- 13: [스레드 풀과 Executor 프레임워크 1](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-13-%EC%8A%A4%EB%A0%88%EB%93%9C-%ED%92%80%EA%B3%BC-executor-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-1)
- 14: [스레드 풀과 Executor 프레임워크 2](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-14-%EC%8A%A4%EB%A0%88%EB%93%9C-%ED%92%80%EA%B3%BC-executor-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-2)

# 섹션 2: 프로세스와 스레드 소개
### 멀티태스킹
- 하나의 CPU 코어가 매우 빠르게 두 프로그램의 코드를 번갈아 수행한다면 두 프로그램이 동시에 실행되는 것처럼 느껴질 것이다. 
- `시분할(Time Sharing)`: 프로그램의 실행 시간을 분할해(스케줄링) 동시에 실행되는 것처럼 하는 기법
- 운영체제가 스케줄링 기법을 이용해 CPU 사용을 배분한다. 
- `멀티태스킹(Multi-Tasking)`: 하나의 컴퓨터 시스템이 동시에 여러 작업을 수행하는 것
- 소프트웨어 기반으로 성능 향상

### 멀티프로세싱
- CPU 코어가 여러개인 경우 실제 물리적으로 동시에 프로그램을 처리할 수 있다. 
- `멀티프로세싱(Multi-Processing)`: 둘 이상의 프로세서(CPU 코어)를 사용하여 여러 작업을 동시에 처리하는 기술
- 하드웨어 기반으로 성능 향상

## 프로세스와 스레드

### 프로세스
- 운영체제 안에서 실행 중인 프로그램
- 프로세스는 프로그램의 인스턴스이다. 
- 각 프로세스는 독립적인 메모리 공간을 가지며, 서로 간섭하지 않고 서로의 메모리에 직접 접근할 수 없다. 운영체제에서 별도의 작업 단위로 분리해서 관리된다. 
- 독립되어 있기 때문에 하나의 프로세스가 충돌해도 다른 프로세스에 영향을 주지 않는다. 
- 메모리 구성
  - `코드 섹션`: 실행할 프로그램의 코드
  - `데이터 섹션`: 전역/정적 변수
  - `힙`: 동적으로 할당되는 메모리 영역
  - `스택`: 메서드 호출 시 생성되는 지역 변수와 반환 주소가 저장되는 영역(스레드에 포함)

### 스레드
- **프로세스는 하나 이상의 스레드를 반드시 포함한다.**
- 프로세스 내에서 실행되는 작업의 단위
- 한 프로세스 내에서 여러 스레드가 존재할 수 있다. 프로세스가 제공하는 메모리 공간을 스레드끼리 공유한다. 
- 스레드는 프로세스보다 단순하므로 생성 및 관리가 단순하고 가볍다. 
- 메모리 구성
  - `공유 메모리`: 같은 프로세스의 메모리 영역 공유
  - `개별 스택`: 각 스레드는 자신만의 스택을 가짐

### 프로그램 실행
- 프로그램을 실행하면 운영체제는 디스크에 있는 프로그램을 메모리로 불러오면서 프로세스를 생성한다. 
- 프로세스 안에 있는 코드가 한 줄씩 실행되면서 프로그램이 실행된다. 
- 실(thread)이 코드를 위에서 아래로 하나씩 꿰면서 내려가는 것과 같다. 프로세스의 코드를 실행하는 흐름을 스레드라고 한다ㅏ. 
- `단일 스레드`: 한 프로세스 내에 하나의 스레드만 존재
- `멀티 스레드`: 한 프로세스 내에 여러 스레드가 존재
- 프로세스는 실행 환경과 자원을 제공하는 컨테이너 역할, 스레드는 CPU를 사용해 코드를 실행

### 멀티스레드가 필요한 이유
- 하나의 프로그램도 그 안에서 동시에 여러 작업이 필요하다. 
  - 유튜브 영상이 재생되는 동안 댓글도 달 수 있어야 함

## 스레드와 스케줄링
### 단일 코어 스케줄링
- 스케줄링 큐에 스레드들이 대기한다. 차례가 된 스레드를 큐에서 꺼내고 CPU를 통해 실행한다. 
- 실행하던 스레드를 잠시 멈추고 스케줄링 큐에 다시 넣는다. 다음 차례의 스레드를 큐에서 꺼내고 CPU를 통해 실행한다. 이 과정을 반복한다. 

### 멀티 코어 스케줄링
- 코어의 개수가 더 많다는 점 외에 단일 코어 스케줄링과 동일하게 동작한다. 

## 컨텍스트 스위칭
- 멀티태스킹 시 스레드를 중단하고 다른 스레드를 실행하는 과정이 빈번하게 발생한다. 이 때 스레드의 코드가 어디까지 수행되었는지 위치를 찾고, 계산하던 변수값을 CPU에 다시 불려들여야 한다. 
- `컨텍스트 스위칭`: 스레드를 멈추는 시점에 CPU에서 사용하던 값들을 메모리에 저장하고, 이후에 그 스레드를 다시 실행할 때 이 값들을 CPU에 다시 불러오는 과정

# 섹션 3: 스레드 생성과 실행
- 자바의 메모리 구조에서 스택 영역은 각 스레드별로 하나의 실행 스택이 생성된다. 즉 스레드 수만큼 스택이 생성된다. 
- 프로세스가 작동하려면 스레드가 최소 하나는 있어야 한다. 자바는 실행 시점에 main이라는 이름의 스레드를 만들고 프로그램의 시작점인 main() 메서드를 실행한다. 
- main() 메서드 내부에서(main 스레드) 새로운 스레드를 생성하고 특정 이름을 부여하지 않으면 자바가 임의의 이름을 부여한다. 
- 새 스레드의 start() 메서드를 호출하면 새 스레드가 시작되면서 **main 스레드가 아닌 새 스레드가 run() 메서드를 실행한다.** 
- main 스레드는 새 스레드에게 실행을 지시하기만 하고 run() 호출에 관여하지 않는다. 이제 main 스레드와 새 스레드는 동시에 실행된다. 
- main 스레드는 새 스레드의 코드를 기다리지 않는다. 
  ```
  main main() start
  main main() end
  Thread-0 : run()
  ```
- 실제 결과를 보면 Thread-0의 run()은 main에서 thread-0.start() 이후이고 main end 이전이지만 main() end가 Thread-0의 결과를 기다리지 않고 먼저 출력되었다. 
- **스레드는 실행 순서와 실행 기간을 보장하지 않는다.**

### `start()` 메서드
- main에서 `run()` 직접 호출
  - 새 스레드의 `start()` 대신 `run()`을 main 메서드에서 직접 실행하면 main 스레드가 사용하는 스택 위에 `run()` 스택 프레임이 올라간다. 
  - `start()`는 스레드에 스택 공간을 할당하면서 스레드를 시작하는 특별한 메서드이다. 이후 해당 스레드에서 `run()` 메서드를 실행한다.

## 데몬 스레드
- 스레드는 사용자(user) 스레드와 데몬(daemon) 스레드로 나눌 수 있다. 
### 사용자 스레드(non-daemon 스레드)
- 프로그램 주 작업 수행
- 작업이 완료될 때까지 실행
- 모든 user 스레드가 종료되면 JVM도 종료

### 데몬 스레드
- 백그라운드에서 보조 작업 수행
- 모든 user 스레드가 종료되면 데몬 스레드는 자동으로 종료

### Thread 상속 vs Runnable 구현
- **스레드 생성 시 Runnable을 구현해 사용하자.** 
- Thread 클래스 상속
  - 장점: 간단한 구현
  - 단점: 상속의 제한(단일 상속만 허용), 유연성 부족(인터페이스보다 유연성 적음)
- Runnable 인터페이스 구현
  - 장점: 상속의 자유로움, 코드 분리(스레드와 실행할 작업의 분리), 여러 스레드가 동일한 Runnable 객체를 공유할 수 있어 효율적인 자원 관리 가능
  - 단점: 코드가 약간 복잡해짐

# 섹션 4: 스레드 제어와 생명 주기 1
## Thread 기본 정보
1. 스레드 생성
   - 스레드 생성 시 Runnable 인터페이스 구현체와 스레드 이름 전달
2. 스레드 객체 정보
  - 객체를 문자열로 변환해 출력
3. 스레드 Id
  - 스레드의 고유 식별자(JVM 내에서 유일)
4. 스레드 이름
   - 생성 시 전달하면 해당 값, 전달하지 않으면 자바가 임의로 설정. 중복 가능
5. 스레드 우선순위
   - 1이 가장 낮고 10이 가장 높음, 기본값은 5
   - 실제 실행 순서는 JVM 구현과 운영체제에 따라 달라질 수 있음
6. 스레드 그룹
   - 스레드가 속한 그룹
   - 기본적으로 모든 스레드는 부모 스레드와 동일한 스레드 그룹에 속하게 됨
   - 부모 스레드: 새로운 스레드를 생성하는 스레드
7. 스레드 상태
   - RUNNABLE: 스레드가 실행 중이거나 실행될 준비가 된 상태
   - NEW: 스레드가 아직 시작되지 않은 상태
   - BLOCKED: 스레드가 동기화 락을 기다리는 상태
   - WAITING: 스레드가 다른 스레드의 특정 작업이 완료되기를 기다리는 상태
   - TIMED_WAITING: 일정 시간 동안 기다리는 상태
   - TERMINATED: 스레드가 실행을 마친 상태

## 스레드 생명주기
- 자바 스레드의 생명주기는 여러 상태로 나뉜다. 각 상태는 스레드가 생성되고 종료되기까지의 과정을 나타낸다. 
### New(생성 상태)
- 스레드가 생성되고 아직 시작되지 않은 상태이다. 

### Runnable(실행 상태)
- 스레드가 실행될 준비가 된 상태이다. 실제 CPU에서 실행될 수 있다. 
- start() 메서드 호출 이후 스레드의 상태이다. 
- Runnable 상태에 있는 모든 스레드가 동시에 실행되는 것은 아니다. 스케줄러가 각 스레드에 CPU 시간을 할당해 실행하기 때문에 실행 대기열에 포함되어 있다가 차례로 CPU에서 실행된다. 
- CPU 실행 스케줄러에 들어가려면 Runnable 상태여야 한다. 
- 즉 운영체제 스케줄러의 실행 대기열에 있든 CPU에서 실제 실행되고 있든 모두 Runnable 상태이다. 자바에서 둘을 구분해서 확인할 수 없다. 

### Blocked(차단 상태)
- 스레드가 다른 스레드에 의해 동기화 락을 얻기 위해 기다리는 상태이다. 

### Waiting(대기 상태)
- 스레드가 다른 스레드의 특정 작업이 완료되기를 무기한 기다리는 상태이다. 

### Timed Waiting(시간 제한 대기 상태)
- 스레드가 특정 시간 동안 다른 스레드의 특정 작업이 완료되기를 기다리는 상태이다.

### Terminated(종료 상태)
- 스레드의 실행이 완료된 상태이다. 
- 스레드가 정상적으로 종료되거나 예외가 발생한 경우 이 상태로 들어간다. 
- 스레드는 한 번 종료되면 다시 시작할 수 없다. 

### 상태 전이 과정
- New -> Runnable: start() 호출
- Runnable -> Blocked/Waiting/Timed Waiting: 스레드가 락을 얻지 못하거나/wait()/sleep()
- Blocked/Waiting/Timed Waiting -> Runnable: 스레드가 락을 얻거나/기다림 완료
- Runnable -> Terminated: 스레드의 run() 메서드 완료

## Runnable의 run()에서의 체크 예외
- Runnable 인터페이스의 run() 메서드를 구현할 때 InterruptedException 체크 예외를 밖으로 던질 수 없는 이유를 알아보자. 
- 자바에서 메서드 재정의 시 규칙
  - 체크 예외
    - 부모 메서드가 체크 예외를 던지지 않는 경우 재정의된 자식 메서드도 체크 예외를 던질 수 없다. 
    - 즉 Runnable 인터페이스의 run()이 체크 예외를 던지지 않기 때문에 오버라이드한 run()도 던질 수 없다. 
  - 언체크(런타임) 예외
    - 예외 처리를 강제하지 않으므로 상관없이 던질 수 있다. 
- **부모 클래스의 메서드를 호출하는 클라이언트 코드는 부모 메서드가 던지는 특정 예외만을 처리하도록 작성된다**. 자식 클래스가 더 넓은 범위의 예외를 던지면 해당 코드는 모든 예외를 제대로 처리하지 못할 수 있다. 
- 즉 부모 클래스가 던지는 예외를 받아서 처리하는 부분에서 해당 예외를 잡지 못하고 런타임 오류를 발생시킬 수 있기 때문에 제한을 하는 것이다. 

### this
- 인스턴스(힙 영역)에서 메서드를 실행하면 어떤 인스턴스에서 호출했는지 기억하기 위해 스택 프레임에 해당 인스턴스의 참조값을 저장한다. 이것이 `this`이다. 

## join
- 필요한 상황: 특정 스레드가 완료(Terminated)될 때까지 기다려야 하는 경우
- 현재 스레드에서 `{선행 스레드}.join()`를 호출하면 된다. `InterruptedException`를 던져야 한다. 
- 선행 스레드가 완료될 때까지 무기한 기다리는 단점이 있다. 

### join - 특정 시간만큼만 대기
- 기존 join의 단점을 보완하기 위해 `{선행 스레드}.join({대기 시간})`처럼 join에 시간을 인자로 전달하면 해당 시간만큼만 대기하다가 그 시간을 초과하면 그냥 종료한다. 
- 이 때 대기하는 스레드의 상태는 Waiting이 아니라 Timed Waiting이 된다. 

# 섹션 5: 스레드 제어와 생명 주기 2
## 인터럽트
- 대기 상태의 스레드를 직접 깨워서 작동하는 Runnable 상태로 만들 수 있다. 
1. `스레드.interrupt()` 메서드를 호출하면 해당 스레드가 인터럽트 상태가 된다. 
2. 인터럽트 상태인 스레드가 InterruptException를 던지는 메서드와 만나면 InterruptException이 발생한다. 
3. InterruptException이 발생하면 스레드가 다시 Runnable 상태가 된다.
- 스레드가 인터럽트 상태인지 확인하기 위해서는 `스레드.isInterrupted()`를 사용한다. 
- 스레드가 인터럽트 상태인지 확인하고 인터럽트 상태라면 Runnable로 변경하기 위해서는 `스레드.interrupted()`를 사용한다. 

## yield
- yield는 양보하다/넘겨주다의 사전적 의미를 가진다. 
- `Thread.yield()` 메서드는 현재 실행중인 스레드가 자발적으로 CPU를 양보해 다른 스레드가 실행될 수 있도록 한다. 
- **`yield()` 메서드를 호출한 스레드는 Runnable 상태를 유지하면서 CPU를 양보한다. 즉 sleep()과 다르게(Waiting) 다시 스케줄링 큐에 들어가면서 CPU 사용 기회를 넘긴다.**
- `sleep()`: Running -> Waiting
- `yield()`: Running -> Runnable

# 섹션 6: 메모리 가시성
## 메모리 가시성
- 메인 메모리는 CPU 입장에서 거리도 멀고 속도도 상대적으로 느리다. 대신 가격이 상대적으로 저렴해 큰 용량을 쉽게 구성할 수 있다. 
- CPU 연산은 매우 빠르기 때문에 이 성능을 따라가려면 CPU 근처에 존재하고 매우 빠른 메모리가 필요하다. 이것이 캐시 메모리이다. 
- 현대의 CPU 대부분은 코어 단위로 각 캐시 메모리를 보유한다. (코어끼리 공유하는 캐시 메모리도 있다) 
- 각 스레드에서 일반 변수의 값을 변경하면 캐시 메모리의 변수값만 변경되고 메인 메모리의 실제 변수값은 변경되지 않는다. 
  - 캐시 메모리의 변수값이 메인 메모리에 언제 반영되냐는 CPU 설계 방식과 종류에 따라 다르기 때문에 알 수 없다.
  - 주로 컨텍스트 스위칭이 될 때 캐시 메모리도 함께 갱신된다. (보장은 아니다)
- **메모리 가시성(memory visibility)**: 멀티스레드 환경에서 한 스레드가 변경한 값이 다른 스레드에서 언제 보이는지에 대한 문제
- 한 스레드에서 변경한 값이 다른 스레드에서 즉시 보이게 하기 위해 `volatile` 키워드를 사용한다.

### volatile
- 메모리 가시성을 해결하려면 해당 값을 캐시가 아닌 메인 메모리에서 직접 접근하도록 하면 된다.
- volatile 키워드로 지정된 변수는 어떤 스레드든 항상 메인 메모리에 직접 값을 반영하고 직접 조회한다. 
- 대신 캐시 메모리 대신 메인 메모리를 사용하므로 성능상 저하가 있다. 따라서 꼭 필요한 부분에만 사용한다. 

## 자바 메모리 모델(JMM)
- Java Memory Model은 자바 프로그램이 어떻게 메모리에 접근하고 수정할 수 있는지를 규정하며, 특히 멀티스레드 프로그래밍에서 스레드 간의 상호작용을 정의한다. 
- **happens-before**: JMM에서 스레드 간의 작업 순서를 정의하는 개념이다. A 작업이 B 작업보다 happens-before 관계에 있다면 A 작업에서의 모든 메모리 변경 사항은 B 작업에서 볼 수 있다. 즉 A 작업에서 변경된 모든 내용은 B 작업이 시작되기 전에 모두 메모리에 반영된다. 
  - 한 동작이 다른 동작보다 먼저 발생함을 보장한다. 
  - 스레드 간 메모리 가시성을 보장하는 규칙이다. 이 규칙을 따르면 멀티스레드 프로그램 작성 시 예상치 못한 동작을 피할 수 있다. 
- happends-before 관계가 발생하는 경우
  - `프로그램 순서 규칙`: 단일 스레드 내에서 프로그램의 순서대로 작성된 모든 명령문은 happends-before 순서로 실행
  - `volatile 변수 규칙`: 변수에 대한 쓰기 작업은 해당 변수를 읽는 모든 스레드에 보이도록 함 -> volatile 변수에 대한 쓰기 작업은 그 변수를 읽는 작업보다 happends-before 관계 형성
  - `스레드 시작 규칙`: 스레드에서 start() 호출 시 호출 이전에 수행된 모든 작업은 호출 이후에 실행된 작업보다 happends-before 관계 형성
  - `스레드 종료 규칙`: join() 호출 시 join() 대상 스레드의 모든 작업은 join() 호출 이후의 작업보다 happends-before 관계 형성
  - `인터럽트 규칙`: interrupt() 호출 시 인터럽트된 스레드가 인터럽트를 감지하는 시점의 작업보다 happends-before 관계 형성
  - `객체 생성 규칙`: 객체 생성자에서 초기화된 필드는 생성자 완료 후 다른 스레드에서 참조될 때 happends-before 관계 형성
  - `모니터 락 규칙`: 한 스레드에서 synchronized 블록 종료 후 그 모니터 락을 얻는 모든 스레드는 해당 블록 내의 모든 작업을 볼 수 있음
  - `전이 규칙`: A가 B보다 happends-before 관계에 있고 B가 C보다 happends-before 관계에 있다면 A가 C보다 happends-before 관계에 있음

- **volatile 또는 스레드 동기화 기법을 사용하면 메모리 가시성 문제가 발생하지 않는다.** 

# 섹션 7: 동기화 - synchronized
- **공유 자원**: 여러 스레드가 접근하는 자원을 의미한다. 대표적인 공유 자원으로 인스턴스의 필드(멤버 변수), 클래스 변수가 있다. 
  - 지역 변수는 스택 영역에 생성되고, 스택 영역은 스레드의 개별 저장 공간이다. 따라서 지역 변수는 공유 자원이 아니다. 
### 임계 영역
- 공유 자원을 여러 단계로 나누어 사용하면 문제가 생길 수 있다. 
- 한번에 하나의 스레드만 로직을 수행하도록 하면 공유 자원 사용 시 발생하는 문제를 제어할 수 있다. 
- **임계 영역(critical section)**: 여러 스레드가 동시에 접근하면 데이터 불일치나 예상치 못한 동작이 발생할 수 있는 위험하고 중요한 코드 부분
  - 임계 영역은 한번에 하나의 스레드만 접근할 수 있도록 안전하게 보호해야 한다. 
- 동기화를 통해 아래 문제를 해결할 수 있다. 
  - `경합 조건(Race condition)`: 두 개 이상의 스레드가 경쟁적으로 동일한 자원을 수정할 때 발생하는 문제
  - `데이터 일관성`: 여러 스레드가 동시에 읽고 쓰는 데이터의 일관성 유지

### synchronized 메서드
- 모든 객체(인스턴스)는 내부에 자신만의 락(lock, 모니터 락)을 가지고 있다.
- **스레드가 synchronized 키워드가 있는 메서드에 진입하려면 반드시 해당 인스턴스의 락이 있어야 한다.**
  - 처음 스레드가 메서드에 접근하면 해당 메서드의 락을 얻고, 이 스레드가 락을 반환하기 전까지 다른 모든 스레드는 메서드에 진입할 수 없다. 
- 메서드 시그니처의 반환 타입 앞에 `synchronized` 키워드를 추가해 사용한다. 

### synchronized 코드 블럭
- 멀티스레드 환경에서 사용하려는 메서드가 synchronized 메서드라면 싱글스레드 환경과 동일한 것이다. 즉 그 메서드를 사용하려는 스레드가 10개였다면 해당 메서드를 수행하기 위해 synchronized 적용 이전에 비해 성능이 10배나 느려질 것이다.
- 따라서 synchronized는 꼭 필요한 곳으로 한정해 설정해야 한다. 즉 synchronized 메서드로 모든 메서드를 임계 영역으로 사용하는 것보다 메서드의 정말 필요한 부분만 임계 영역으로 설정하는 것이 좋다. 
- synchronized(this) {} 의 코드 블럭 안에 코드를 작성하여 임계 영역을 설정할 수 있다.

### synchronized 장단점
- 장점
  - 자동 잠금 해제: synchronized 메서드/블럭 완료 시 자동으로 락 대기중인 다른 스레드의 잠금이 해제된다. 
- 단점
  - 무한 대기: BLOCKED 상태 스레드는 락이 풀릴 때까지 무한 대기한다. 
  - 공정성: 락이 돌아왔을 때 BLOCKED 상태의 스레드들 중 어떤 스레드가 락을 획득할 지 알 수 없다(스케줄링의 starvation). 

# 섹션 8: 고급 동기화 - concurrent.Lock
## LockSupport
- synchronized의 단점을 해결하기 위해 더 유연하고 세밀한 방법이 필요하다. 
- **LockSupport 라이브러리**를 이용해 해결할 수 있다. 
- LockSupport 기능 
  - park(): 스레드를 WAITING 상태로 변경한다.
  - parkNanos(나노초): 스레드를 나노초 동안만 TIMED_WAITING 상태로 변경한다. 
  - unpark(스레드): 지정한 WAITING 상태의 스레드를 RUNNABLE 상태로 변경한다. 
    - 대기 중인 스레드는 스스로 깨어날 수 없기 때문에 외부 스레드에서 지정해 깨워야 한다. 

### BLOCKED vs WAITING(TIMED_WAITING)
- 인터럽트 관점
  - BLOCKED 상태는 인터럽트가 걸려도 대기 상태를 빠져나오지 못한다. 
  - WAITING 상태는 인터럽트가 걸리면 대기 상태를 빠져나와 RUNNABLE 상태가 된다. 
- 용도
  - BLOCKED는 자바의 synchronized에서 락을 획득하기 위해 대기할 때 사용된다. 
  - WAITING은 다양한 대기 상태 메서드 호출 시 사용된다. join(), park(), wait()등의 메서드 호출 시 WAITING 상태가 된다. 
- WAITING과 TIMED_WAITING은 서로 짝이 있다. 
- BLOCKED, WAITING, TIMED_WAITING 모두 스레드가 대기하며 실행 스케줄링에 들어가지 않는다. 
- LockSupport는 BLOCKED 상태가 무한 대기한다는 단점을 보완하기 위해 인터럽트로 빠져나올 수 있고, parkNanos()를 도입해 TIMED_WAITING 상태가 되어 스스로 깨어날 수 있게 했다. 
- 하지만 LockSupport가 제공하는 기능은 너무 저수준이다. park(), unPark()등 개발자가 직접 구현해야 한다. 

## ReentrantLock
- 자바는 위 문제를 해결하기 위해 Lock 인터페이스와 ReentrantLock 구현체를 제공한다.
- 메서드
  - lock(): 락을 획득하는 메서드이다. 여기서의 lock은 객체 내부의 모니터 락이 아니다(모니터 락은 synchronized에서만 사용된다). 다른 스레드가 락을 획득했다면 현재 스레드는 WAITING 상태가 된다. 이 메서드는 인터럽트에 반응하지 않는다. 
  - lockInterruptibly(): lock 메서드와 동일하지만 대기 중에 인터럽트가 발생하면 InterruptedException이 발생하며 락 획득을 포기한다. 
  - tryLock(): 락 획득을 시도하고 즉시 성공 여부를 반환한다. 즉 현재 락을 얻을 수 없다면 즉시 포기한다.
  - tryLock(time, unit): tryLock()과 같지만 주어진 시간 동안 대기한다. 인터럽트 발생 시 반응한다. 
  - unlock(): 락을 해제한다. 락 획득을 대기 중인 다른 스레드 중 하나가 락을 획득하게 된다. 락을 획득한 스레드가 호출해야 하고 아니라면 IllegalMonitorStateException이 발생할 수 있다. 
  - newCondition(): 스레드가 특정 조건을 기다리거나 신호를 받을 수 있게 한다. 
- 위의 메서드를 통해 LockSupport보다 유연하고 고수준의 기능을 사용할 수 있다. 
- ReentrantLock 구현체는 공정 모드와 비공정 모드를 제공한다. 
- 비공정 모드(Non-fair Mode): 기본 모드, 락을 먼저 요청한 스레드가 락을 먼저 획득한다는 보장이 없다.
  - 성능 우선: 락 획득 속도가 빠름
  - 선점 가능: 기존 대기 스레드보다 먼저 락을 획득할 수 있음
  - 기아 현상: 특정 스레드가 계속해서 락을 획득하지 못할 수 있음
- 공정 모드(Fair Mode): 락을 먼저 요청한 스레드가 락을 먼저 획득한다고 보장한다. 
  - 공정성 보장: 대기 큐에서 먼저 대기한 스레드가 먼저 락 획득
  - 기아 현상 방지: 모든 스레드가 언젠가는 락 획득 가능
  - 성능 저하: 락 획득 속도가 느려질 수 있음

# 섹션 9: 생산자 소비자 문제 1
- 생산자-소비자 문제는 멀티스레드 프로그래밍에서 자주 등장하는 동시성 문제로, 여러 스레드가 동시에 데이터를 생산하고 소비하는 상황을 말한다. 
- **생산자(Producer)**: 데이터를 생성하는 역할
- **소비자(Consumer)**: 생성된 데이터를 사용하는 역할
- **버퍼(buffer)**: 생산자가 생성한 데이터를 일시적으로 저장하는 공간, 한정된 크기를 가지며 생산자와 소비자가 버퍼를 통해 데이터를 주고받음

### 생산자-소비자 문제
- 생산자가 너무 빠른 경우: 버퍼가 가득 차서 생산자는 버퍼에 빈 공간이 생길 때까지 기다려야 함
- 소비자가 너무 빠른 경우: 버퍼가 비어서 소비자는 버퍼에 새로운 데이터가 들어올 때까지 기다려야 함
- 생산자-소비자 문제(producer-consumer problem): 한정된 버퍼 문제(bounded-buffer problem)으로도 불린다. 생산자 스레드와 소비자 스레드가 특정 자원을 함께 생산하고 소비하며 발생하는 문제이다. 버퍼의 크기가 한정되어있기 때문에 발생한다. 

### Object - wait(), nofity()
- Object.wait()
  - 현재 스레드가 가진 락을 반납하고 WAITING이 된다. 
  - 현재 스레드가 synchronized 블럭이거나 메서드에서 락을 소유하고 있을 때만 호출할 수 있다. 이렇게 대기 상태로 전환된 스레드는 다른 스레드가 notify()나 notifyAll()를 호출할 때까지 대기한다.
- Object.notify()
  - 대기 중인 스레드 중 하나를 깨운다. 
  - notify()로 깨어난 스레드는 여전히 임계 영역 안에 있다. **깨어난 스레드는 대기 집합에서 벗어나지만 락을 획득하기 위해 BLOCKED 상태로 대기한다.** 즉 현재 스레드(notify를 호출한 스레드)가 락을 반환할 때까지 대기한다.
  - synchronized 블럭 안에서 호출되어야 한다. 깨운 스레드는 락을 다시 획득할 기회를 얻는다.- **notify()는 어떤 스레드를 깨우는지 알 수 없다.** 객체의 대기 집합은 하나이기 때문에 생산자 스레드가 소비자 스레드를 콕 집어 깨울 수 없다. 스레드 기아 현상이 발생할 수도 있다.
- Object.notifyAll()
  - 대기 중인 모든 스레드를 깨운다. 
  - 대기 중인 모든 스레드는 락을 획득하기 위해 BLOCKED 상태가 된다. 그 중 하나씩 락을 획득하고 각자의 wait() 이후 코드를 실행한다. 
  - 모든 대기 중인 스레드가 대기 집합에서 나오기 때문에 기아 문제는 해결할 수 있다. 하지만 여전히 비효율적이다. 
- 모든 객체는 각자의 대기 집합을 가지고 있다.  
- **깨어난 스레드는 임계 영역의 코드 중 wait()을 호출한 부분부터 실행된다. 이때 락을 획득하면 wait() 이후 코드를 실행한다.**

# 섹션 10: 생산자 소비자 문제 2
# 섹션 11: CAS - 동기화와 원자적 연산
# 섹션 12: 동시성 컬렉션
# 섹션 13: 스레드 풀과 Executor 프레임워크 1
# 섹션 14: 스레드 풀과 Executor 프레임워크 2