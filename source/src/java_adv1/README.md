# 목차
- 2: [프로세스와 스레드 소개](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-2-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%86%8C%EA%B0%9C)
- 3: [스레드 생성과 실행](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-3-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%83%9D%EC%84%B1%EA%B3%BC-%EC%8B%A4%ED%96%89)
- 4: [스레드 제어와 생명 주기 1](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-4-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%A0%9C%EC%96%B4%EC%99%80-%EC%83%9D%EB%AA%85-%EC%A3%BC%EA%B8%B0-1)
- 5: [스레드 제어와 생명 주기 2](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-5-%EC%8A%A4%EB%A0%88%EB%93%9C-%EC%A0%9C%EC%96%B4%EC%99%80-%EC%83%9D%EB%AA%85-%EC%A3%BC%EA%B8%B0-2)
- 6: [메모리 가시성](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-6-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B0%80%EC%8B%9C%EC%84%B1)
- 7: [동기화 - synchronized](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-7-%EB%8F%99%EA%B8%B0%ED%99%94---synchronized)
- 8: [고급 동기화 - concurrent.Lock](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-8-%EA%B3%A0%EA%B8%89-%EB%8F%99%EA%B8%B0%ED%99%94---concurrentlock)
- 9: [생산자 소비자 문제 1](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-9-%EC%83%9D%EC%82%B0%EC%9E%90-%EC%86%8C%EB%B9%84%EC%9E%90-%EB%AC%B8%EC%A0%9C-1)
- 10: [생산자 소비자 문제 1](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-10-%EC%83%9D%EC%82%B0%EC%9E%90-%EC%86%8C%EB%B9%84%EC%9E%90-%EB%AC%B8%EC%A0%9C-2)
- 11: [CAS - 동기화와 원자적 연산](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-11-cas---%EB%8F%99%EA%B8%B0%ED%99%94%EC%99%80-%EC%9B%90%EC%9E%90%EC%A0%81-%EC%97%B0%EC%82%B0)
- 12: [동시성 컬렉션](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-12-%EB%8F%99%EC%8B%9C%EC%84%B1-%EC%BB%AC%EB%A0%89%EC%85%98)
- 13: [스레드 풀과 Executor 프레임워크 1](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-13-%EC%8A%A4%EB%A0%88%EB%93%9C-%ED%92%80%EA%B3%BC-executor-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-1)
- 14: [스레드 풀과 Executor 프레임워크 2](https://github.com/nahowo/java-lecture/tree/main/source/src/java_adv1#%EC%84%B9%EC%85%98-14-%EC%8A%A4%EB%A0%88%EB%93%9C-%ED%92%80%EA%B3%BC-executor-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-2)

# 섹션 2: 프로세스와 스레드 소개
### 멀티태스킹
- 하나의 CPU 코어가 매우 빠르게 두 프로그램의 코드를 번갈아 수행한다면 두 프로그램이 동시에 실행되는 것처럼 느껴질 것이다. 
- `시분할(Time Sharing)`: 프로그램의 실행 시간을 분할해(스케줄링) 동시에 실행되는 것처럼 하는 기법
- 운영체제가 스케줄링 기법을 이용해 CPU 사용을 배분한다. 
- `멀티태스킹(Multi-Tasking)`: 하나의 컴퓨터 시스템이 동시에 여러 작업을 수행하는 것
- 소프트웨어 기반으로 성능 향상

### 멀티프로세싱
- CPU 코어가 여러개인 경우 실제 물리적으로 동시에 프로그램을 처리할 수 있다. 
- `멀티프로세싱(Multi-Processing)`: 둘 이상의 프로세서(CPU 코어)를 사용하여 여러 작업을 동시에 처리하는 기술
- 하드웨어 기반으로 성능 향상

## 프로세스와 스레드

### 프로세스
- 운영체제 안에서 실행 중인 프로그램
- 프로세스는 프로그램의 인스턴스이다. 
- 각 프로세스는 독립적인 메모리 공간을 가지며, 서로 간섭하지 않고 서로의 메모리에 직접 접근할 수 없다. 운영체제에서 별도의 작업 단위로 분리해서 관리된다. 
- 독립되어 있기 때문에 하나의 프로세스가 충돌해도 다른 프로세스에 영향을 주지 않는다. 
- 메모리 구성
  - `코드 섹션`: 실행할 프로그램의 코드
  - `데이터 섹션`: 전역/정적 변수
  - `힙`: 동적으로 할당되는 메모리 영역
  - `스택`: 메서드 호출 시 생성되는 지역 변수와 반환 주소가 저장되는 영역(스레드에 포함)

### 스레드
- **프로세스는 하나 이상의 스레드를 반드시 포함한다.**
- 프로세스 내에서 실행되는 작업의 단위
- 한 프로세스 내에서 여러 스레드가 존재할 수 있다. 프로세스가 제공하는 메모리 공간을 스레드끼리 공유한다. 
- 스레드는 프로세스보다 단순하므로 생성 및 관리가 단순하고 가볍다. 
- 메모리 구성
  - `공유 메모리`: 같은 프로세스의 메모리 영역 공유
  - `개별 스택`: 각 스레드는 자신만의 스택을 가짐

### 프로그램 실행
- 프로그램을 실행하면 운영체제는 디스크에 있는 프로그램을 메모리로 불러오면서 프로세스를 생성한다. 
- 프로세스 안에 있는 코드가 한 줄씩 실행되면서 프로그램이 실행된다. 
- 실(thread)이 코드를 위에서 아래로 하나씩 꿰면서 내려가는 것과 같다. 프로세스의 코드를 실행하는 흐름을 스레드라고 한다ㅏ. 
- `단일 스레드`: 한 프로세스 내에 하나의 스레드만 존재
- `멀티 스레드`: 한 프로세스 내에 여러 스레드가 존재
- 프로세스는 실행 환경과 자원을 제공하는 컨테이너 역할, 스레드는 CPU를 사용해 코드를 실행

### 멀티스레드가 필요한 이유
- 하나의 프로그램도 그 안에서 동시에 여러 작업이 필요하다. 
  - 유튜브 영상이 재생되는 동안 댓글도 달 수 있어야 함

## 스레드와 스케줄링
### 단일 코어 스케줄링
- 스케줄링 큐에 스레드들이 대기한다. 차례가 된 스레드를 큐에서 꺼내고 CPU를 통해 실행한다. 
- 실행하던 스레드를 잠시 멈추고 스케줄링 큐에 다시 넣는다. 다음 차례의 스레드를 큐에서 꺼내고 CPU를 통해 실행한다. 이 과정을 반복한다. 

### 멀티 코어 스케줄링
- 코어의 개수가 더 많다는 점 외에 단일 코어 스케줄링과 동일하게 동작한다. 

## 컨텍스트 스위칭
- 멀티태스킹 시 스레드를 중단하고 다른 스레드를 실행하는 과정이 빈번하게 발생한다. 이 때 스레드의 코드가 어디까지 수행되었는지 위치를 찾고, 계산하던 변수값을 CPU에 다시 불려들여야 한다. 
- `컨텍스트 스위칭`: 스레드를 멈추는 시점에 CPU에서 사용하던 값들을 메모리에 저장하고, 이후에 그 스레드를 다시 실행할 때 이 값들을 CPU에 다시 불러오는 과정

# 섹션 3: 스레드 생성과 실행
- 자바의 메모리 구조에서 스택 영역은 각 스레드별로 하나의 실행 스택이 생성된다. 즉 스레드 수만큼 스택이 생성된다. 
- 프로세스가 작동하려면 스레드가 최소 하나는 있어야 한다. 자바는 실행 시점에 main이라는 이름의 스레드를 만들고 프로그램의 시작점인 main() 메서드를 실행한다. 
- main() 메서드 내부에서(main 스레드) 새로운 스레드를 생성하고 특정 이름을 부여하지 않으면 자바가 임의의 이름을 부여한다. 
- 새 스레드의 start() 메서드를 호출하면 새 스레드가 시작되면서 **main 스레드가 아닌 새 스레드가 run() 메서드를 실행한다.** 
- main 스레드는 새 스레드에게 실행을 지시하기만 하고 run() 호출에 관여하지 않는다. 이제 main 스레드와 새 스레드는 동시에 실행된다. 
- main 스레드는 새 스레드의 코드를 기다리지 않는다. 
  ```
  main main() start
  main main() end
  Thread-0 : run()
  ```
- 실제 결과를 보면 Thread-0의 run()은 main에서 thread-0.start() 이후이고 main end 이전이지만 main() end가 Thread-0의 결과를 기다리지 않고 먼저 출력되었다. 
- **스레드는 실행 순서와 실행 기간을 보장하지 않는다.**

### `start()` 메서드
- main에서 `run()` 직접 호출
  - 새 스레드의 `start()` 대신 `run()`을 main 메서드에서 직접 실행하면 main 스레드가 사용하는 스택 위에 `run()` 스택 프레임이 올라간다. 
  - `start()`는 스레드에 스택 공간을 할당하면서 스레드를 시작하는 특별한 메서드이다. 이후 해당 스레드에서 `run()` 메서드를 실행한다.

## 데몬 스레드
- 스레드는 사용자(user) 스레드와 데몬(daemon) 스레드로 나눌 수 있다. 
### 사용자 스레드(non-daemon 스레드)
- 프로그램 주 작업 수행
- 작업이 완료될 때까지 실행
- 모든 user 스레드가 종료되면 JVM도 종료

### 데몬 스레드
- 백그라운드에서 보조 작업 수행
- 모든 user 스레드가 종료되면 데몬 스레드는 자동으로 종료

### Thread 상속 vs Runnable 구현
- **스레드 생성 시 Runnable을 구현해 사용하자.** 
- Thread 클래스 상속
  - 장점: 간단한 구현
  - 단점: 상속의 제한(단일 상속만 허용), 유연성 부족(인터페이스보다 유연성 적음)
- Runnable 인터페이스 구현
  - 장점: 상속의 자유로움, 코드 분리(스레드와 실행할 작업의 분리), 여러 스레드가 동일한 Runnable 객체를 공유할 수 있어 효율적인 자원 관리 가능
  - 단점: 코드가 약간 복잡해짐

# 섹션 4: 스레드 제어와 생명 주기 1
## Thread 기본 정보
1. 스레드 생성
   - 스레드 생성 시 Runnable 인터페이스 구현체와 스레드 이름 전달
2. 스레드 객체 정보
  - 객체를 문자열로 변환해 출력
3. 스레드 Id
  - 스레드의 고유 식별자(JVM 내에서 유일)
4. 스레드 이름
   - 생성 시 전달하면 해당 값, 전달하지 않으면 자바가 임의로 설정. 중복 가능
5. 스레드 우선순위
   - 1이 가장 낮고 10이 가장 높음, 기본값은 5
   - 실제 실행 순서는 JVM 구현과 운영체제에 따라 달라질 수 있음
6. 스레드 그룹
   - 스레드가 속한 그룹
   - 기본적으로 모든 스레드는 부모 스레드와 동일한 스레드 그룹에 속하게 됨
   - 부모 스레드: 새로운 스레드를 생성하는 스레드
7. 스레드 상태
   - RUNNABLE: 스레드가 실행 중이거나 실행될 준비가 된 상태
   - NEW: 스레드가 아직 시작되지 않은 상태
   - BLOCKED: 스레드가 동기화 락을 기다리는 상태
   - WAITING: 스레드가 다른 스레드의 특정 작업이 완료되기를 기다리는 상태
   - TIMED_WAITING: 일정 시간 동안 기다리는 상태
   - TERMINATED: 스레드가 실행을 마친 상태

## 스레드 생명주기
- 자바 스레드의 생명주기는 여러 상태로 나뉜다. 각 상태는 스레드가 생성되고 종료되기까지의 과정을 나타낸다. 
### New(생성 상태)
- 스레드가 생성되고 아직 시작되지 않은 상태이다. 

### Runnable(실행 상태)
- 스레드가 실행될 준비가 된 상태이다. 실제 CPU에서 실행될 수 있다. 
- start() 메서드 호출 이후 스레드의 상태이다. 
- Runnable 상태에 있는 모든 스레드가 동시에 실행되는 것은 아니다. 스케줄러가 각 스레드에 CPU 시간을 할당해 실행하기 때문에 실행 대기열에 포함되어 있다가 차례로 CPU에서 실행된다. 
- CPU 실행 스케줄러에 들어가려면 Runnable 상태여야 한다. 
- 즉 운영체제 스케줄러의 실행 대기열에 있든 CPU에서 실제 실행되고 있든 모두 Runnable 상태이다. 자바에서 둘을 구분해서 확인할 수 없다. 

### Blocked(차단 상태)
- 스레드가 다른 스레드에 의해 동기화 락을 얻기 위해 기다리는 상태이다. 

### Waiting(대기 상태)
- 스레드가 다른 스레드의 특정 작업이 완료되기를 무기한 기다리는 상태이다. 

### Timed Waiting(시간 제한 대기 상태)
- 스레드가 특정 시간 동안 다른 스레드의 특정 작업이 완료되기를 기다리는 상태이다.

### Terminated(종료 상태)
- 스레드의 실행이 완료된 상태이다. 
- 스레드가 정상적으로 종료되거나 예외가 발생한 경우 이 상태로 들어간다. 
- 스레드는 한 번 종료되면 다시 시작할 수 없다. 

### 상태 전이 과정
- New -> Runnable: start() 호출
- Runnable -> Blocked/Waiting/Timed Waiting: 스레드가 락을 얻지 못하거나/wait()/sleep()
- Blocked/Waiting/Timed Waiting -> Runnable: 스레드가 락을 얻거나/기다림 완료
- Runnable -> Terminated: 스레드의 run() 메서드 완료

## Runnable의 run()에서의 체크 예외
- Runnable 인터페이스의 run() 메서드를 구현할 때 InterruptedException 체크 예외를 밖으로 던질 수 없는 이유를 알아보자. 
- 자바에서 메서드 재정의 시 규칙
  - 체크 예외
    - 부모 메서드가 체크 예외를 던지지 않는 경우 재정의된 자식 메서드도 체크 예외를 던질 수 없다. 
    - 즉 Runnable 인터페이스의 run()이 체크 예외를 던지지 않기 때문에 오버라이드한 run()도 던질 수 없다. 
  - 언체크(런타임) 예외
    - 예외 처리를 강제하지 않으므로 상관없이 던질 수 있다. 
- **부모 클래스의 메서드를 호출하는 클라이언트 코드는 부모 메서드가 던지는 특정 예외만을 처리하도록 작성된다**. 자식 클래스가 더 넓은 범위의 예외를 던지면 해당 코드는 모든 예외를 제대로 처리하지 못할 수 있다. 
- 즉 부모 클래스가 던지는 예외를 받아서 처리하는 부분에서 해당 예외를 잡지 못하고 런타임 오류를 발생시킬 수 있기 때문에 제한을 하는 것이다. 

### this
- 인스턴스(힙 영역)에서 메서드를 실행하면 어떤 인스턴스에서 호출했는지 기억하기 위해 스택 프레임에 해당 인스턴스의 참조값을 저장한다. 이것이 `this`이다. 

## join
- 필요한 상황: 특정 스레드가 완료(Terminated)될 때까지 기다려야 하는 경우
- 현재 스레드에서 `{선행 스레드}.join()`를 호출하면 된다. `InterruptedException`를 던져야 한다. 
- 선행 스레드가 완료될 때까지 무기한 기다리는 단점이 있다. 

### join - 특정 시간만큼만 대기
- 기존 join의 단점을 보완하기 위해 `{선행 스레드}.join({대기 시간})`처럼 join에 시간을 인자로 전달하면 해당 시간만큼만 대기하다가 그 시간을 초과하면 그냥 종료한다. 
- 이 때 대기하는 스레드의 상태는 Waiting이 아니라 Timed Waiting이 된다. 

# 섹션 5: 스레드 제어와 생명 주기 2
## 인터럽트
- 대기 상태의 스레드를 직접 깨워서 작동하는 Runnable 상태로 만들 수 있다. 
1. `스레드.interrupt()` 메서드를 호출하면 해당 스레드가 인터럽트 상태가 된다. 
2. 인터럽트 상태인 스레드가 InterruptException를 던지는 메서드와 만나면 InterruptException이 발생한다. 
3. InterruptException이 발생하면 스레드가 다시 Runnable 상태가 된다.
- 스레드가 인터럽트 상태인지 확인하기 위해서는 `스레드.isInterrupted()`를 사용한다. 
- 스레드가 인터럽트 상태인지 확인하고 인터럽트 상태라면 Runnable로 변경하기 위해서는 `스레드.interrupted()`를 사용한다. 

## yield
- yield는 양보하다/넘겨주다의 사전적 의미를 가진다. 
- `Thread.yield()` 메서드는 현재 실행중인 스레드가 자발적으로 CPU를 양보해 다른 스레드가 실행될 수 있도록 한다. 
- **`yield()` 메서드를 호출한 스레드는 Runnable 상태를 유지하면서 CPU를 양보한다. 즉 sleep()과 다르게(Waiting) 다시 스케줄링 큐에 들어가면서 CPU 사용 기회를 넘긴다.**
- `sleep()`: Running -> Waiting
- `yield()`: Running -> Runnable

# 섹션 6: 메모리 가시성
## 메모리 가시성
- 메인 메모리는 CPU 입장에서 거리도 멀고 속도도 상대적으로 느리다. 대신 가격이 상대적으로 저렴해 큰 용량을 쉽게 구성할 수 있다. 
- CPU 연산은 매우 빠르기 때문에 이 성능을 따라가려면 CPU 근처에 존재하고 매우 빠른 메모리가 필요하다. 이것이 캐시 메모리이다. 
- 현대의 CPU 대부분은 코어 단위로 각 캐시 메모리를 보유한다. (코어끼리 공유하는 캐시 메모리도 있다) 
- 각 스레드에서 일반 변수의 값을 변경하면 캐시 메모리의 변수값만 변경되고 메인 메모리의 실제 변수값은 변경되지 않는다. 
  - 캐시 메모리의 변수값이 메인 메모리에 언제 반영되냐는 CPU 설계 방식과 종류에 따라 다르기 때문에 알 수 없다.
  - 주로 컨텍스트 스위칭이 될 때 캐시 메모리도 함께 갱신된다. (보장은 아니다)
- **메모리 가시성(memory visibility)**: 멀티스레드 환경에서 한 스레드가 변경한 값이 다른 스레드에서 언제 보이는지에 대한 문제
- 한 스레드에서 변경한 값이 다른 스레드에서 즉시 보이게 하기 위해 `volatile` 키워드를 사용한다.

### volatile
- 메모리 가시성을 해결하려면 해당 값을 캐시가 아닌 메인 메모리에서 직접 접근하도록 하면 된다.
- volatile 키워드로 지정된 변수는 어떤 스레드든 항상 메인 메모리에 직접 값을 반영하고 직접 조회한다. 
- 대신 캐시 메모리 대신 메인 메모리를 사용하므로 성능상 저하가 있다. 따라서 꼭 필요한 부분에만 사용한다. 

## 자바 메모리 모델(JMM)
- Java Memory Model은 자바 프로그램이 어떻게 메모리에 접근하고 수정할 수 있는지를 규정하며, 특히 멀티스레드 프로그래밍에서 스레드 간의 상호작용을 정의한다. 
- **happens-before**: JMM에서 스레드 간의 작업 순서를 정의하는 개념이다. A 작업이 B 작업보다 happens-before 관계에 있다면 A 작업에서의 모든 메모리 변경 사항은 B 작업에서 볼 수 있다. 즉 A 작업에서 변경된 모든 내용은 B 작업이 시작되기 전에 모두 메모리에 반영된다. 
  - 한 동작이 다른 동작보다 먼저 발생함을 보장한다. 
  - 스레드 간 메모리 가시성을 보장하는 규칙이다. 이 규칙을 따르면 멀티스레드 프로그램 작성 시 예상치 못한 동작을 피할 수 있다. 
- happends-before 관계가 발생하는 경우
  - `프로그램 순서 규칙`: 단일 스레드 내에서 프로그램의 순서대로 작성된 모든 명령문은 happends-before 순서로 실행
  - `volatile 변수 규칙`: 변수에 대한 쓰기 작업은 해당 변수를 읽는 모든 스레드에 보이도록 함 -> volatile 변수에 대한 쓰기 작업은 그 변수를 읽는 작업보다 happends-before 관계 형성
  - `스레드 시작 규칙`: 스레드에서 start() 호출 시 호출 이전에 수행된 모든 작업은 호출 이후에 실행된 작업보다 happends-before 관계 형성
  - `스레드 종료 규칙`: join() 호출 시 join() 대상 스레드의 모든 작업은 join() 호출 이후의 작업보다 happends-before 관계 형성
  - `인터럽트 규칙`: interrupt() 호출 시 인터럽트된 스레드가 인터럽트를 감지하는 시점의 작업보다 happends-before 관계 형성
  - `객체 생성 규칙`: 객체 생성자에서 초기화된 필드는 생성자 완료 후 다른 스레드에서 참조될 때 happends-before 관계 형성
  - `모니터 락 규칙`: 한 스레드에서 synchronized 블록 종료 후 그 모니터 락을 얻는 모든 스레드는 해당 블록 내의 모든 작업을 볼 수 있음
  - `전이 규칙`: A가 B보다 happends-before 관계에 있고 B가 C보다 happends-before 관계에 있다면 A가 C보다 happends-before 관계에 있음

- **volatile 또는 스레드 동기화 기법을 사용하면 메모리 가시성 문제가 발생하지 않는다.** 

# 섹션 7: 동기화 - synchronized
- **공유 자원**: 여러 스레드가 접근하는 자원을 의미한다. 대표적인 공유 자원으로 인스턴스의 필드(멤버 변수), 클래스 변수가 있다. 
  - 지역 변수는 스택 영역에 생성되고, 스택 영역은 스레드의 개별 저장 공간이다. 따라서 지역 변수는 공유 자원이 아니다. 
### 임계 영역
- 공유 자원을 여러 단계로 나누어 사용하면 문제가 생길 수 있다. 
- 한번에 하나의 스레드만 로직을 수행하도록 하면 공유 자원 사용 시 발생하는 문제를 제어할 수 있다. 
- **임계 영역(critical section)**: 여러 스레드가 동시에 접근하면 데이터 불일치나 예상치 못한 동작이 발생할 수 있는 위험하고 중요한 코드 부분
  - 임계 영역은 한번에 하나의 스레드만 접근할 수 있도록 안전하게 보호해야 한다. 
- 동기화를 통해 아래 문제를 해결할 수 있다. 
  - `경합 조건(Race condition)`: 두 개 이상의 스레드가 경쟁적으로 동일한 자원을 수정할 때 발생하는 문제
  - `데이터 일관성`: 여러 스레드가 동시에 읽고 쓰는 데이터의 일관성 유지

### synchronized 메서드
- 모든 객체(인스턴스)는 내부에 자신만의 락(lock, 모니터 락)을 가지고 있다.
- **스레드가 synchronized 키워드가 있는 메서드에 진입하려면 반드시 해당 인스턴스의 락이 있어야 한다.**
  - 처음 스레드가 메서드에 접근하면 해당 메서드의 락을 얻고, 이 스레드가 락을 반환하기 전까지 다른 모든 스레드는 메서드에 진입할 수 없다. 
- 메서드 시그니처의 반환 타입 앞에 `synchronized` 키워드를 추가해 사용한다. 

### synchronized 코드 블럭
- 멀티스레드 환경에서 사용하려는 메서드가 synchronized 메서드라면 싱글스레드 환경과 동일한 것이다. 즉 그 메서드를 사용하려는 스레드가 10개였다면 해당 메서드를 수행하기 위해 synchronized 적용 이전에 비해 성능이 10배나 느려질 것이다.
- 따라서 synchronized는 꼭 필요한 곳으로 한정해 설정해야 한다. 즉 synchronized 메서드로 모든 메서드를 임계 영역으로 사용하는 것보다 메서드의 정말 필요한 부분만 임계 영역으로 설정하는 것이 좋다. 
- synchronized(this) {} 의 코드 블럭 안에 코드를 작성하여 임계 영역을 설정할 수 있다.

### synchronized 장단점
- 장점
  - 자동 잠금 해제: synchronized 메서드/블럭 완료 시 자동으로 락 대기중인 다른 스레드의 잠금이 해제된다. 
- 단점
  - 무한 대기: BLOCKED 상태 스레드는 락이 풀릴 때까지 무한 대기한다. 
  - 공정성: 락이 돌아왔을 때 BLOCKED 상태의 스레드들 중 어떤 스레드가 락을 획득할 지 알 수 없다(스케줄링의 starvation). 

# 섹션 8: 고급 동기화 - concurrent.Lock
## LockSupport
- synchronized의 단점을 해결하기 위해 더 유연하고 세밀한 방법이 필요하다. 
- **LockSupport 라이브러리**를 이용해 해결할 수 있다. 
- LockSupport 기능 
  - park(): 스레드를 WAITING 상태로 변경한다.
  - parkNanos(나노초): 스레드를 나노초 동안만 TIMED_WAITING 상태로 변경한다. 
  - unpark(스레드): 지정한 WAITING 상태의 스레드를 RUNNABLE 상태로 변경한다. 
    - 대기 중인 스레드는 스스로 깨어날 수 없기 때문에 외부 스레드에서 지정해 깨워야 한다. 

### BLOCKED vs WAITING(TIMED_WAITING)
- 인터럽트 관점
  - BLOCKED 상태는 인터럽트가 걸려도 대기 상태를 빠져나오지 못한다. 
  - WAITING 상태는 인터럽트가 걸리면 대기 상태를 빠져나와 RUNNABLE 상태가 된다. 
- 용도
  - BLOCKED는 자바의 synchronized에서 락을 획득하기 위해 대기할 때 사용된다. 
  - WAITING은 다양한 대기 상태 메서드 호출 시 사용된다. join(), park(), wait()등의 메서드 호출 시 WAITING 상태가 된다. 
- WAITING과 TIMED_WAITING은 서로 짝이 있다. 
- BLOCKED, WAITING, TIMED_WAITING 모두 스레드가 대기하며 실행 스케줄링에 들어가지 않는다. 
- LockSupport는 BLOCKED 상태가 무한 대기한다는 단점을 보완하기 위해 인터럽트로 빠져나올 수 있고, parkNanos()를 도입해 TIMED_WAITING 상태가 되어 스스로 깨어날 수 있게 했다. 
- 하지만 LockSupport가 제공하는 기능은 너무 저수준이다. park(), unPark()등 개발자가 직접 구현해야 한다. 

## ReentrantLock
- 자바는 위 문제를 해결하기 위해 Lock 인터페이스와 ReentrantLock 구현체를 제공한다.
- 메서드
  - lock(): 락을 획득하는 메서드이다. 여기서의 lock은 객체 내부의 모니터 락이 아니다(모니터 락은 synchronized에서만 사용된다). 다른 스레드가 락을 획득했다면 현재 스레드는 WAITING 상태가 된다. 이 메서드는 인터럽트에 반응하지 않는다. 
  - lockInterruptibly(): lock 메서드와 동일하지만 대기 중에 인터럽트가 발생하면 InterruptedException이 발생하며 락 획득을 포기한다. 
  - tryLock(): 락 획득을 시도하고 즉시 성공 여부를 반환한다. 즉 현재 락을 얻을 수 없다면 즉시 포기한다.
  - tryLock(time, unit): tryLock()과 같지만 주어진 시간 동안 대기한다. 인터럽트 발생 시 반응한다. 
  - unlock(): 락을 해제한다. 락 획득을 대기 중인 다른 스레드 중 하나가 락을 획득하게 된다. 락을 획득한 스레드가 호출해야 하고 아니라면 IllegalMonitorStateException이 발생할 수 있다. 
  - newCondition(): 스레드가 특정 조건을 기다리거나 신호를 받을 수 있게 한다. 
- 위의 메서드를 통해 LockSupport보다 유연하고 고수준의 기능을 사용할 수 있다. 
- ReentrantLock 구현체는 공정 모드와 비공정 모드를 제공한다. 
- 비공정 모드(Non-fair Mode): 기본 모드, 락을 먼저 요청한 스레드가 락을 먼저 획득한다는 보장이 없다.
  - 성능 우선: 락 획득 속도가 빠름
  - 선점 가능: 기존 대기 스레드보다 먼저 락을 획득할 수 있음
  - 기아 현상: 특정 스레드가 계속해서 락을 획득하지 못할 수 있음
- 공정 모드(Fair Mode): 락을 먼저 요청한 스레드가 락을 먼저 획득한다고 보장한다. 
  - 공정성 보장: 대기 큐에서 먼저 대기한 스레드가 먼저 락 획득
  - 기아 현상 방지: 모든 스레드가 언젠가는 락 획득 가능
  - 성능 저하: 락 획득 속도가 느려질 수 있음

# 섹션 9: 생산자 소비자 문제 1
- 생산자-소비자 문제는 멀티스레드 프로그래밍에서 자주 등장하는 동시성 문제로, 여러 스레드가 동시에 데이터를 생산하고 소비하는 상황을 말한다. 
- **생산자(Producer)**: 데이터를 생성하는 역할
- **소비자(Consumer)**: 생성된 데이터를 사용하는 역할
- **버퍼(buffer)**: 생산자가 생성한 데이터를 일시적으로 저장하는 공간, 한정된 크기를 가지며 생산자와 소비자가 버퍼를 통해 데이터를 주고받음

### 생산자-소비자 문제
- 생산자가 너무 빠른 경우: 버퍼가 가득 차서 생산자는 버퍼에 빈 공간이 생길 때까지 기다려야 함
- 소비자가 너무 빠른 경우: 버퍼가 비어서 소비자는 버퍼에 새로운 데이터가 들어올 때까지 기다려야 함
- 생산자-소비자 문제(producer-consumer problem): 한정된 버퍼 문제(bounded-buffer problem)으로도 불린다. 생산자 스레드와 소비자 스레드가 특정 자원을 함께 생산하고 소비하며 발생하는 문제이다. 버퍼의 크기가 한정되어있기 때문에 발생한다. 

### Object - wait(), nofity()
- Object.wait()
  - 현재 스레드가 가진 락을 반납하고 WAITING이 된다. 
  - 현재 스레드가 synchronized 블럭이거나 메서드에서 락을 소유하고 있을 때만 호출할 수 있다. 이렇게 대기 상태로 전환된 스레드는 다른 스레드가 notify()나 notifyAll()를 호출할 때까지 대기한다.
- Object.notify()
  - 대기 중인 스레드 중 하나를 깨운다. 
  - notify()로 깨어난 스레드는 여전히 임계 영역 안에 있다. **깨어난 스레드는 대기 집합에서 벗어나지만 락을 획득하기 위해 BLOCKED 상태로 대기한다.** 즉 현재 스레드(notify를 호출한 스레드)가 락을 반환할 때까지 대기한다.
  - synchronized 블럭 안에서 호출되어야 한다. 깨운 스레드는 락을 다시 획득할 기회를 얻는다.- **notify()는 어떤 스레드를 깨우는지 알 수 없다.** 객체의 대기 집합은 하나이기 때문에 생산자 스레드가 소비자 스레드를 콕 집어 깨울 수 없다. 스레드 기아 현상이 발생할 수도 있다.
- Object.notifyAll()
  - 대기 중인 모든 스레드를 깨운다. 
  - 대기 중인 모든 스레드는 락을 획득하기 위해 BLOCKED 상태가 된다. 그 중 하나씩 락을 획득하고 각자의 wait() 이후 코드를 실행한다. 
  - 모든 대기 중인 스레드가 대기 집합에서 나오기 때문에 기아 문제는 해결할 수 있다. 하지만 여전히 비효율적이다. 
- 모든 객체는 각자의 대기 집합을 가지고 있다.  
- **깨어난 스레드는 임계 영역의 코드 중 wait()을 호출한 부분부터 실행된다. 이때 락을 획득하면 wait() 이후 코드를 실행한다.**

# 섹션 10: 생산자 소비자 문제 2
## Condition
```java
private final Lock lock = new ReentrantLock();
private final Condition condition = lock.newCondition();
```
- 위처럼 사용할 수 있다. 
- Condition.await()
  - 지정한 condition에 현재 스레드를 WAITING 상태로 보관한다. ReentrantLock에서 획득한 락(모니터 락과 다름)을 반납하고 대기 상태로 condition에 보관된다. 
- Condition.signal()
  - 지정한 condition에서 대기중인 스레드를 하나 깨운다. 깨어난 스레드는 condition에서 빠져나온다. 
- Condition을 분리하면 대기 공간을 여러개로 만들어 현재 스레드를 특정 대기 공간에 보관하고, 특정 대기 공간에서 대기중인 스레드들만 깨울 수 있다.

### Object.notify() vs Condition.signal()
- **Object.notify()**
  - 대기 집합의 스레드 중 하나를 선택해 깨운다. 깨우는 순서는 정의되지 않으며 JVM 구현에 따라 다르다. 
  - synchronized 블록 내에 모니터 락을 가지고 있는 스레드가 호출해야 한다. 
- **Condition.signal()**
  - 대기 중인 스레드 중 하나를 깨우며, 일반적으로 FIFO 순을 따른다. 자바 버전과 구현에 따라 달라질 수 있지만 보통 queue 구조를 사용한다. 
  - ReentrantLock을 가지고 있는 스레드가 호출해야 한다. 

## 스레드의 대기
### synchronized 대기
- 대기 1: 락 획득 대기
  - BLOCKED 상태
  - synchronized 진입 시 모니터 락이 없으면 시작됨
  - 다른 스레드가 synchronized를 빠져나갈 때 대기가 풀리며 락 획득 시도
- 대기 2: wait() 대기
  - WAITING 상태
  - wait() 호출 시 스레드 대기 집합에서 대기
  - 다른 스레드가 notify() 호출 시 대기 집합에서 벗어나 대기 1 상태가 됨
- 자바 내부적으로 락을 기다리는 BLOCKED 상태의 스레드들을 관리한다(대기 2의 대기 집합처럼 락 대기 집합들이 존재). 
- 자바의 모든 객체 인스턴스는 멀티스레드와 임계 영역을 다루기 위해 내부에 3가지 기본 요소를 가진다.
  1. 모니터 락
  2. 락 대기 집합(모니터 락 대기 집합)
  3. 스레드 대기 집합
- 락 대기 집합이 1차 대기소이고, 스레드 대기 집합이 2차 대기소이다. 2차 대기소에 들어간 스레드는 2차, 1차 대기소를 모두 빠져나와야 임계 영역을 수행할 수 있다. 

## BlockingQueue 인터페이스
- 데이터 추가 차단: 큐가 가득 차면 데이터 추가 작업을 시도하는 스레드는 공간이 생길 때까지 차단된다. 
- 데이터 획득 차단: 큐가 비어 있으면 데이터 획득 작업을 시도하는 스레드는 큐에 데이터가 들어올 때까지 차단된다. 
- 대표적인 구현체로 ArrayBlockingQueue(배열 기반, 버퍼 크기 고정), LinkedBlockingQueue(링크 기반, 버퍼 크기 고정/무한)가 있다. 

# 섹션 11: CAS - 동기화와 원자적 연산
## 원자적 연산
- 원자적 연산(atomic operation): 더 이상 나눌 수 없는 단위로 수행되는 연산을 의미한다.
- i = 1은 원자적 연산이다. i += 1(i ++)은 원자적 연산이 아니다. 
- 원자적 연산이 아닌 연산은 멀티스레드 상황에서 문제가 생길 수 있다.
### Volatile
- 연산에서 사용하는 변수에 Volatile을 적용해도 문제는 해결되지 않는다. Volatile은 캐시 메모리 대신 메인 메모리를 직접 사용하도록 하는 것이지 연산 자체를 묶어주지 않는다. 

### synchronized
- synchronized를 통해 안전한 임계 영역을 만들 수 있다. 원자적 연산을 멀티스레드 상황에서 안전하게 사용할 수 있다. 

## AtomicInteger
- 멀티스레드 상황에서 안전한 값 증가/감소 연산을 제공한다. AtomicLong, AtomicBoolean 등 다양한 클래스가 존재한다. 
### synchronized vs AtomicInteger 성능 비교
- AtomicInteger가 락을 사용하는 synchronized, reentrantLock보다 빠르다. 
- AtomicInteger은 임계 영역을 만들지 않고(락을 사용하지 않고), 원자적 연산을 만들어낸다. 

## CAS 연산
- CAS(Compare-And-Swap): 락을 사용하지 않는 락 프리 기법이다. 락을 완전히 대체할 수는 없고 작은 단위의 일부 영역에 적용할 수 있다. 
- compareAndSet(a, b): 현재 값이 a면 b로 변경한다. 이 연산은 원자적 연산이다. 
  1. 메인 메모리에 있는 값을 확인한다.  
  2. 해당 값이 a라면 b로 변경한다. 
- CPU 하드웨어의 지원: 소프트웨어가 아니라 하드웨어가 원자적이지 않은 연산을 특별하게 하나의 원자적인 연산으로 묶어서 제공한다. 대부분의 현대 CPU는 CAS 연산을 위한 명령어를 제공한다. 
  - CPU가 1, 2번 연산 사이에 다른 스레드가 해당 값에 접근하지 못하도록 막는다. 이 연산 사이는 굉장히 작기 때문에 성능에 크게 영향을 미치지 않는다. 
```java
    private static int incrementAnsGet(AtomicInteger atomicInteger) {
        int getValue;
        boolean result;
        do {
            getValue = atomicInteger.get();
            log("getValue: " + getValue);
            result = atomicInteger.compareAndSet(getValue, getValue + 1);
            log("result: " + result);
        } while (!result);
        return getValue + 1;
    }
```
- 기존 값 + 1 연산을 무조건 원자적으로 수행할 때까지 while문을 돈다. 
- getValue = atomicInteger.get(); 줄에서 확인한 값이 atomicInteger.compareAndSet(getValue, getValue + 1); 를 통해 중간에 변경되지 않았다는 것이 검증되면 기존 값 + 1을 반환한다. 
- 이때 반환 시 get()으로 반환하면 중간에 다른 스레드에서 값을 변경할 수 있기 때문에 무조건 기존값 + 1을 반환해야 한다. **즉 compareAndSet은 값이 변경되었는지 아닌지 여부를 확인하는 데만 사용되고 실제 값은 기존값 + 1이 되어야 한다.**  
- 스레드 충돌이 발생할 때마다 CAS를 다시 실행하므로 락 없이 데이터를 안전하게 변경할 수 있다. 
- 충돌이 드물게 발생하는 환경에서 높은 성능을 보인다. 스레드 대기 시간과 오버헤드가 줄어든다. 간단한 연산의 경우 CPU 연산에서는 충돌이 자주 발생하지 않는다. 
- 충돌이 빈번하게 발생하는 환경에서는 CPU 자원을 많이 소모하게 된다. 

### CAS vs 락 방식
- 락
  - 비관적 접근(충돌이 일어날 것이라고 가정)
  - 데이터에 접근하기 전에 항상 락을 획득
  - 다른 스레드의 접근을 막음
- CAS
  - 낙관적 접근(충돌이 일어나지 않을 것이라고 가정)
  - 데이터에 바로 접근
  - 충돌이 발생하면 그때 재시도
- 간단한 연산에서는 충돌이 자주 발생하지 않기 때문에 CAS를 사용하는 것이 효과적이다. (충돌 발생 횟수 < 충돌이 발생하지 않는 횟수)

## CAS를 활용한 락(Spin Lock)
- 락이 해제되기를 기다리며 반복 확인하는 모습 때문에 스핀 락이라는 이름이 붙었다. 바쁜 대기(busy wait)이라고도 한다. 
- 락 획득 시 아래의 연산을 원자적으로 만들어야 한다. 
  1. 락 사용 여부 확인
  2. 락의 값 변경
- 이를 위해 AtomicBoolean을 사용한다. atomicBoolean.compareAndSet(false, true)를 통해 락이 false인지 확인하고 false라면 현재 스레드가 락을 가지도록 true로 만드는 과정을 원자적으로 수행한다. 

### CAS 단점
- 오래 걸리는 로직에서 스핀 락을 사용하면 CPU 사용률이 증가한다. 동기화 락을 사용하는 방식보다 스핀 락을 사용하는 방식이 더 효율적인 경우에 사용해야 한다.  

# 섹션 12: 동시성 컬렉션
- 여러 스레드가 동시에 접근해도 괜찮은 경우를 스레드 세이프(Thread safe)하다고 표현한다. 
- 컬렉션 프레임워크가 제공하는 대부분의 연산은 원자적이지 않기 때문에 스레드 세이프하지 않다. synchronized를 통해 동기화를 유지해야 한다. 

## 프록시
- 모든 컬렉션 프레임워크의 개별 메서드에 synchronized를 추가하는 대신 프록시(Proxy; 대리자)에게 대신 동기화를 처리하도록 할 수 있다. 
- 프록시 클래스는 생성자를 통해 기존 클래스를 target으로 주입받는다. 이때 프록시 클래스는 target과 같은 인터페이스를 구현한다. 모든 메서드에 synchronized를 걸고, target의 기능을 호출하는 역할만 수행한다. 
- 클라이언트 -> 프록시 -> 타켓 클래스(서버) 형식의 구조를 가진다. 
- 클라이언트 입장에서 보면 프록시는 원본과 동일하게 생겼다(동일한 인터페이스를 구현하므로). 따라서 호출할 메서드가 똑같다. 원본 코드를 전혀 손대지 않고도 프록시를 통해 동기화 기능을 적용했다. 

### 프록시 패턴
- 프록시 패턴은 어떤 객체에 대한 접근을 제어하기 위해 그 객체의 대리인/인터페이스 역할을 하는 객체를 제공하는 객체지향 디자인 패턴이다. 
- 프록시 객체는 실제 객체에 대한 참조를 유지하며 그 객체에 접근하거나 행동을 수행하기 전에 추가적인 처리를 할 수 있도록 한다. 
- 접근 제어, 성능 향상(실제 객체 생성 지연/캐싱), 부가 기능 제공(로깅, 인증, 동기화 등)의 목적으로 사용한다.
- 스프링의 AOP는 이런 프록시 패턴을 극한으로 적용하는 예이다. 

## 자바 동시성 컬렉션 - synchronized
- 자바는 컬렉션을 위한 프록시 기능을 제공한다. `Collections.synchronizedXXX(XXX)`처럼 타겟 컬렉션을 전달해 프록시 객체를 만들어 사용한다.
- 단점
  - 동기화 오버헤드 발생
  - 전체 컬렉션에 대한 동기화로 인해 잠금 범위가 넓음 -> 잠금 경합 증가, 병렬처리 효율성 저하
  - 정교한 동기화 불가능 -> 특정 부분이나 메서드에 대해 선택적으로 동기화를 적용하는 것은 어려움

# 섹션 13: 스레드 풀과 Executor 프레임워크 1
### 스레드를 직접 사용할 때의 문제점
1. 스레드 생성 시간으로 인한 성능 문제
   - 메모리 할당: 스레드는 자신만의 콜 스택을 가진다. 콜 스택은 스레드가 실행되는 동안 사용하는 메모리 공간이다. 따라서 이 공간을 위한 메모리를 할당해야 한다. 
   - 운영체제 자원 사용: 스레드 생성 작업은 운영체제 커널 수준에서 이루어지며 시스템 콜을 통해 처리된다. 따라서 CPU와 메모리 리소스를 소모한다. 
   - 운영체제 스케줄러 설정: 새 스레드가 생성되면 운영체제의 스케줄러는 이 스레드를 관리하고 실행 순서를 조정해야 한다. 스케줄링 알고리즘에 따라 추가적인 오버헤드가 발생할 수 있다. 
- 위 문제를 해결하기 위해 생성한 스레드를 재사용할 수 있다. 
2. 스레드 관리 문제
   - 서버의 CPU, 메모리 자원이 한정되어 있기 때문에 스레드를 무한하게 만들 수 없다. 
   - 애플리케이션 종료 시 안전한 종료를 위한 관리가 필요하다. 
3. Runnable 인터페이스의 불편함
  - 반환 값이 없음: 스레드 실행 결과를 직접 받을 수 없다. 
  - 예외 처리: 체크 예외를 던질 수 없고 메서드 내부에서 처리해야 한다. 

## 스레드 풀 - Executor 프레임워크
- 위의 문제를 해결하기 위해 스레드 풀을 사용할 수 있다. 하지만 스레드 풀을 직접 구현하려고 하면 상태 관리, 생산자-소비자 문제 등 복잡하기 때문에 자바에서 지원하는 Executor 프레임워크를 사용한다. 
### ExecutorService - ThreadPoolExecutor
- `ExecutorService` 인터페이스의 `ThreadPoolExecutor` 구현체를 사용해 스레드 풀을 편리하게 관리할 수 있다. 
- 크게 2가지 요소로 구성된다. 
  1. 스레드 풀: 스레드 관리
  2. `BlockingQueue`: 작업 보관; 생산자-소비자 문제 해결을 위해 큐 대신 BlockingQueue 사용
- `ThreadPoolExecutor` 생성자
  - `corePoolSize`: 스레드 풀에서 관리되는 기본 스레드 수
  - `maximumPoolSize`: 스레드 풀에서 관리되는 최대 스레드 수
  - `keepAliveTime`, `TimeUnit`: 기본 스레드 수를 초과해 만들어진 스레드가 생존할 수 있는 대기 시간, 이 시간 동안 처리할 작업이 없다면 초과 스레드는 제거됨
  - `workQueue`: 작업을 보관할 블로킹 큐 
- `Executors가` 제공하는 `newFixedThreadPool(size)`를 이용해 편리하게 `ExecutorService`를 생성할 수 있다. 

## Future
- `Runnable` vs `Callable`
  - `Runnable` 인터페이스의 run() 메서드는 반환 타입이 void이다. 또 예외가 선언되어있지 않기 때문에 해당 인터페이스를 구현하는 모든 메서드는 체크 예외를 던질 수 없다. 
  - `Callable` 인터페이스의 call() 메서드는 반환 타입이 제네릭이기 때문에 값을 반환할 수 있다. `throws Exception`이 선언되어 있어 해당 인터페이스를 구현하는 모든 메서드는 체크 예외를 던질 수 있다. 
- Future는 submit()의 호출로 반환받는 결과의 타입이다. 
  - submit() 이후 즉시 결과를 반환받는 것은 불가능하다. 결과를 반환받는 Callable의 call() 메서드는 submit()을 호출하는 스레드가 실행하는 것이 아니고 스레드 풀의 다른 스레드가 실행하기 때문에 언제 실행되어 결과를 반환받을지 알 수 없다. 
  - 따라서 submit()은 결과를 나중에 받을 수 있는 Future 객체를 대신 제공한다. Future는 전달한 작업의 미래 결과를 담고 있다.
- 블로킹(Blocking): 스레드가 어떤 결과를 받기 위해 대기하는 것
  - Future의 상태가 완료 상태가 아니라면 요청 스레드는 결과를 받기 위해 블로킹 상태로 대기한다. 
### Future가 필요한 이유
- Future가 없다면 결과를 받을 때까지 요청 스레드는 대기 상태(블로킹 상태)로 대기해야 한다. 따라서 다른 작업을 동시에 수행할 수 없다.  
- Future를 사용할 때는 future.get()을 호출할 때만 블로킹 상태가 된다. 즉 submit()으로 원하는 모든 스레드를 던진 뒤 한번에 get()을 호출해야 요청 스레드가 멀티스레드를 처리할 수 있다(여러 스레드를 동시에 요청할 수 있다). 만약 submit(), get()을 같이 묶어 호출한다면 싱글스레드 환경과 동일한 시간이 걸린다.

# 섹션 14: 스레드 풀과 Executor 프레임워크 2